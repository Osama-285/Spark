{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2a52ec6-76ee-459c-be95-3015d6def2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://25980bb9571e:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>FlightData</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f9d32535580>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from pyspark.sql import SparkSession\n",
    "\n",
    "# spark = SparkSession.builder \\\n",
    "#         .appName(\"FlightData\")\\\n",
    "#         .getOrCreate()\n",
    "\n",
    "# spark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"FlightData\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba39cb1-8568-4d26-b4de-23fc2fd75026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+------+-----------+--------------------+----------------------+--------------------+----------+----------+\n",
      "|flightNumber|airline|origin|destination|           dayOfWeek|scheduledDepartureTime|scheduledArrivalTime| validFrom|   validTo|\n",
      "+------------+-------+------+-----------+--------------------+----------------------+--------------------+----------+----------+\n",
      "|         425|  GoAir| Delhi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-15 05:45:00|                NULL|28-10-2018|30-03-2019|\n",
      "|         423|  GoAir| Delhi|  Hyderabad|            Saturday|   2025-04-15 07:30:00|                NULL|28-10-2018|28-10-2018|\n",
      "|         423|  GoAir| Delhi|  Hyderabad|              Friday|   2025-04-15 07:30:00|                NULL|03-11-2018|01-12-2018|\n",
      "|         423|  GoAir| Delhi|  Hyderabad|              Friday|   2025-04-15 07:30:00|                NULL|02-02-2019|30-03-2019|\n",
      "|         423|  GoAir| Delhi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-15 07:30:00|                NULL|29-10-2018|30-11-2018|\n",
      "+------------+-------+------+-----------+--------------------+----------------------+--------------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- flightNumber: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      " |-- dayOfWeek: string (nullable = true)\n",
      " |-- scheduledDepartureTime: timestamp (nullable = true)\n",
      " |-- scheduledArrivalTime: timestamp (nullable = true)\n",
      " |-- validFrom: string (nullable = true)\n",
      " |-- validTo: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"Flight_Schedule.csv\")\n",
    "# df.show(5)\n",
    "# df.printSchema()\n",
    "\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"Flight_Schedule.csv\")\n",
    "df.show(5)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12fda273-0794-4e71-85a5-22476b418a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----------+-----------+-------------+-----------+-------------+-----------+--------------+------------+\n",
      "|flightNumber|      airline|     origin|destination|validFromDate|validToDate|validFromYear|validToYear|validFromMonth|validToMonth|\n",
      "+------------+-------------+-----------+-----------+-------------+-----------+-------------+-----------+--------------+------------+\n",
      "|         304|        GoAir| Port Blair|    Chennai|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         407|        GoAir|Bhubaneswar|    Kolkata|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         405|    Air India|  Khajuraho|   Varanasi|   2018-10-29| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         441|    Air India| Aurangabad|     Mumbai|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         569|    Air India|    Chennai|     Mumbai|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         477|    Air India|      Delhi|     Raipur|   2018-10-30| 2018-11-28|         2018|       2018|            10|          11|\n",
      "|         729|    Air India|    Kolkata|   Guwahati|   2018-10-29| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|        3754|    Air India|    Silchar|    Kolkata|   2018-12-01| 2018-12-01|         2018|       2018|            12|          12|\n",
      "|        3754|    Air India|    Silchar|    Kolkata|   2018-12-29| 2018-12-29|         2018|       2018|            12|          12|\n",
      "|        1478|AirAsia India|      Surat|  Bengaluru|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         894|  Jet Airways|     Bhopal|      Delhi|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         358|  Jet Airways|      Delhi|     Mumbai|   2018-12-15| 2019-03-30|         2018|       2019|            12|           3|\n",
      "|         448|  Jet Airways|  Bengaluru|     Mumbai|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         308|   TestIndigo|  Hyderabad|      Delhi|   2018-10-29| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|        5448|   TestIndigo|     Mumbai|      Delhi|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         568|   TestIndigo|     Mumbai|      Kochi|   2018-10-30| 2019-03-26|         2018|       2019|            10|           3|\n",
      "|         191|   TestIndigo|      Delhi|     Mumbai|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         318|   TestIndigo|    Kolkata|     Mumbai|   2018-10-31| 2019-03-27|         2018|       2019|            10|           3|\n",
      "|         467|   TestIndigo|  Hyderabad|     Jaipur|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "|         436|   TestIndigo|     Nagpur|  Bengaluru|   2018-10-28| 2019-03-30|         2018|       2019|            10|           3|\n",
      "+------------+-------------+-----------+-----------+-------------+-----------+-------------+-----------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import col, to_date, year, dayofmonth, month\n",
    "# splitDate = df.withColumn(\"validFromDate\", to_date(col(\"ValidFrom\"), \"dd-MM-yyyy\")) \\\n",
    "#                 .withColumn(\"validFromYear\", year(col(\"validFromDate\"))) \\\n",
    "#                 .withColumn(\"validFromMonth\", month(col(\"validFromDate\"))) \\\n",
    "#                 .withColumn(\"validFromDay\", dayofmonth(col(\"validFromDate\"))) \\\n",
    "#                 .withColumn(\"validToDate\", to_date(col(\"ValidTo\"), \"dd-MM-yyyy\")) \\\n",
    "#                 .withColumn(\"validToYear\", year(col(\"validToDate\"))) \\\n",
    "#                 .withColumn(\"validToMonth\", month(col(\"validToDate\"))) \\\n",
    "#                 .withColumn(\"validToDay\", dayofmonth(col(\"validToDate\")))\n",
    "\n",
    "# splitDate.select(\"flightNumber\",\"airline\",\"origin\",\"destination\",\"validFromDate\", \"validToDate\", \"validFromYear\",\"validToYear\",\"validFromMonth\",\"validToMonth\") \\\n",
    "#             .distinct().show()\n",
    "\n",
    "# from pyspark.sql.types import IntegerType\n",
    "\n",
    "# df = df.withColumn(\"flightNumber\", df[\"flightNumber\"].cast(IntegerType()))\n",
    "# df.printSchema()\n",
    "\n",
    "from pyspark.sql.functions import col, to_date, year, dayofmonth, month\n",
    "\n",
    "splitDate = df.withColumn(\"validFromDate\", to_date(col(\"ValidFrom\"), \"dd-MM-yyyy\")) \\\n",
    "                .withColumn(\"validFromYear\", year(col(\"validFromDate\"))) \\\n",
    "                .withColumn(\"validFromMonth\", month(col(\"validFromDate\"))) \\\n",
    "                .withColumn(\"validFromDay\", dayofmonth(col(\"validFromDate\"))) \\\n",
    "                .withColumn(\"validToDate\", to_date(col(\"ValidTo\"), \"dd-MM-yyyy\")) \\\n",
    "                .withColumn(\"validToYear\", year(col(\"validToDate\"))) \\\n",
    "                .withColumn(\"validToMonth\", month(col(\"validToDate\"))) \\\n",
    "                .withColumn(\"validToDay\", dayofmonth(col(\"validToDate\")))\n",
    "\n",
    "splitDate.select(\"flightNumber\",\"airline\",\"origin\",\"destination\",\"validFromDate\", \"validToDate\", \"validFromYear\",\"validToYear\",\"validFromMonth\",\"validToMonth\") \\\n",
    "             .distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83d3c42-2149-4570-9d55-9d7911509a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after removing nulls:\n",
      "+------------+-------+---------+-----------+--------------------+----------------------+--------------------+----------+----------+-------------+-------------+--------------+------------+-----------+-----------+------------+----------+\n",
      "|flightNumber|airline|   origin|destination|           dayOfWeek|scheduledDepartureTime|scheduledArrivalTime| validFrom|   validTo|validFromDate|validFromYear|validFromMonth|validFromDay|validToDate|validToYear|validToMonth|validToDay|\n",
      "+------------+-------+---------+-----------+--------------------+----------------------+--------------------+----------+----------+-------------+-------------+--------------+------------+-----------+-----------+------------+----------+\n",
      "|         559|  GoAir|  Lucknow|  Hyderabad|Sunday,Tuesday,We...|   2025-04-15 15:45:00| 2025-04-15 17:45:00|28-10-2018|30-03-2019|   2018-10-28|         2018|            10|          28| 2019-03-30|       2019|           3|        30|\n",
      "|         580|  GoAir|    Kochi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-15 04:45:00| 2025-04-15 06:15:00|28-10-2018|30-03-2019|   2018-10-28|         2018|            10|          28| 2019-03-30|       2019|           3|        30|\n",
      "|         587|  GoAir|    Kochi|  Hyderabad|Sunday,Tuesday,We...|   2025-04-15 17:20:00| 2025-04-15 19:20:00|28-10-2018|30-03-2019|   2018-10-28|         2018|            10|          28| 2019-03-30|       2019|           3|        30|\n",
      "|         587|  GoAir|    Kochi|  Hyderabad|              Monday|   2025-04-15 17:50:00| 2025-04-15 19:20:00|28-10-2018|30-03-2019|   2018-10-28|         2018|            10|          28| 2019-03-30|       2019|           3|        30|\n",
      "|         553|  GoAir|Ahmedabad|  Hyderabad|Sunday,Monday,Tue...|   2025-04-15 11:05:00| 2025-04-15 12:45:00|29-10-2018|30-03-2019|   2018-10-29|         2018|            10|          29| 2019-03-30|       2019|           3|        30|\n",
      "+------------+-------+---------+-----------+--------------------+----------------------+--------------------+----------+----------+-------------+-------------+--------------+------------+-----------+-----------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Original row count: 34325\n",
      "Cleaned row count: 11976\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import col\n",
    "# filtered_df = df1.filter((col(\"origin\") == \"Delhi\") &\n",
    "#                         (col(\"destination\") == \"Hyderabad\") &\n",
    "#                         (col(\"dayOfWeek\").contains(\"Saturday\")))\n",
    "\n",
    "# filtered_df.show()\n",
    "\n",
    "# from pyspark.sql.types import IntegerType, DoubleType\n",
    "# splitDate = splitDate.withColumn(\"flightNumber\", df[\"flightNumber\"].cast(IntegerType()))\n",
    "# splitDate.createOrReplaceTempView(\"flights\")\n",
    "\n",
    "# sqlAirline = \"\"\"\n",
    "#         SELECT flightNumber, airline, COUNT(airline) as totalFlight\n",
    "#         FROM flights\n",
    "#         WHERE airline IS NOT NULL AND flightNumber IS NOT NULL\n",
    "#         GROUP BY flightNumber,airline\n",
    "#         ORDER BY flightNumber ASC\"\"\"\n",
    "# flightData = spark.sql(sqlAirline)\n",
    "# flightData.show()\n",
    "# from pyspark.sql.types import IntegerType, StringType\n",
    "# splitDate= splitDate.withColumn(\"flightNumber\", splitDate[\"flightNumber\"].cast(IntegerType()))\n",
    "# splitDate.createOrReplaceTempView(\"flights\")\n",
    "\n",
    "# flightSQL = \"\"\"\n",
    "#         SELECT DISTINCT flightNumber, airline, origin,destination,COUNT(airline) as TotalFlight, validFromYear, validToYear\n",
    "#         FROM flights\n",
    "#         WHERE airline IS NOT NULL AND flightNumber IS NOT NULL\n",
    "#         GROUP BY flightNumber, airline, origin,destination, validFromYear, validToYear\n",
    "#         ORDER BY flightNumber DESC\"\"\"\n",
    "# flightData = spark.sql(flightSQL)\n",
    "# flightData.show()\n",
    "\n",
    "df_cleaned = splitDate.na.drop()\n",
    "print(\"DataFrame after removing nulls:\")\n",
    "df_cleaned.show(5)\n",
    "\n",
    "print(f\"Original row count: {splitDate.count()}\")\n",
    "print(f\"Cleaned row count: {df_cleaned.count()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5c369dd-e3e4-468e-aa87-08cf65369a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------------+------------------+-----------+-------------+-----------+\n",
      "|flightNumber|    airline|            origin|       destination|TotalFlight|validFromYear|validToYear|\n",
      "+------------+-----------+------------------+------------------+-----------+-------------+-----------+\n",
      "|        9820|Jet Airways|            Imphal|           Kolkata|          1|         2018|       2019|\n",
      "|        9819|Jet Airways|           Kolkata|            Imphal|          1|         2018|       2019|\n",
      "|        9818|Jet Airways|          Srinagar|             Delhi|          1|         2018|       2019|\n",
      "|        9817|Jet Airways|             Delhi|          Srinagar|          1|         2018|       2019|\n",
      "|        8964|   SpiceJet|Thiruvananthapuram|             Delhi|          1|         2019|       2020|\n",
      "|        8964|   SpiceJet|Thiruvananthapuram|             Delhi|          1|         2020|       2020|\n",
      "|        8963|   SpiceJet|             Delhi|Thiruvananthapuram|          1|         2020|       2020|\n",
      "|        8963|   SpiceJet|             Delhi|Thiruvananthapuram|          1|         2019|       2020|\n",
      "|        8956|   SpiceJet|         Ahmedabad|             Delhi|          1|         2019|       2020|\n",
      "|        8939|   SpiceJet|          Srinagar|             Delhi|          1|         2020|       2020|\n",
      "|        8938|   SpiceJet|             Delhi|              Pune|          1|         2018|       2019|\n",
      "|        8938|   SpiceJet|             Delhi|              Pune|          1|         2019|       2020|\n",
      "|        8938|   SpiceJet|             Delhi|              Pune|          1|         2020|       2020|\n",
      "|        8937|   SpiceJet|              Pune|             Delhi|          1|         2019|       2020|\n",
      "|        8937|   SpiceJet|              Pune|             Delhi|          1|         2018|       2019|\n",
      "|        8937|   SpiceJet|              Pune|             Delhi|          1|         2019|       2019|\n",
      "|        8937|   SpiceJet|              Pune|             Delhi|          1|         2020|       2020|\n",
      "|        8920|   SpiceJet|            Mumbai|             Delhi|          1|         2020|       2020|\n",
      "|        8913|   SpiceJet|             Delhi|         Ahmedabad|          1|         2018|       2019|\n",
      "|        8913|   SpiceJet|             Delhi|         Ahmedabad|          1|         2019|       2019|\n",
      "+------------+-----------+------------------+------------------+-----------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# flight_count = filtered_df.count()\n",
    "# print(f\"Number of Delhi-Hyderabad Saturday flights: {flight_count}\")\n",
    "# flightData20 = flightData.filter(flightData[\"totalFlight\"] > 30)\n",
    "# flightData10 = flightData20.filter(flightData20[\"totalFlight\"] > 10)\n",
    "\n",
    "# flightData20.show()\n",
    "# flightData10.show()\n",
    "\n",
    "# flightData.write.partitionBy(\"airline\").parquet(\"output\")\n",
    "df_cleaned.createOrReplaceTempView(\"flights\")\n",
    "flightSQL = \"\"\"\n",
    "    SELECT DISTINCT flightNumber, airline, origin,destination,COUNT(airline) as TotalFlight, validFromYear, validToYear\n",
    "          FROM flights\n",
    "          WHERE airline IS NOT NULL AND flightNumber IS NOT NULL\n",
    "          GROUP BY flightNumber, airline, origin,destination, validFromYear, validToYear\n",
    "          ORDER BY flightNumber DESC\"\"\"\n",
    "\n",
    "flightData = spark.sql(flightSQL)\n",
    "flightData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ec1113a-4a73-449b-b129-e4979c604328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-------------+-----------+-------------+-----------+\n",
      "|flightNumber|       origin|  destination|TotalFlight|validFromYear|validToYear|\n",
      "+------------+-------------+-------------+-----------+-------------+-----------+\n",
      "|        2601|       Mumbai|       Nagpur|          1|         2019|       2020|\n",
      "|        2610|        Kochi|Visakhapatnam|          1|         2019|       2019|\n",
      "|        2606|          Goa|       Mumbai|          1|         2019|       2020|\n",
      "|        2601|       Mumbai|       Nagpur|          1|         2020|       2021|\n",
      "|        2603|       Mumbai|       Indore|          1|         2020|       2020|\n",
      "|        2606|          Goa|       Mumbai|          1|         2020|       2020|\n",
      "|        2604|       Indore|       Mumbai|          1|         2020|       2020|\n",
      "|        2607|       Mumbai|       Jaipur|          1|         2020|       2020|\n",
      "|        2608|       Jaipur|       Mumbai|          1|         2019|       2020|\n",
      "|        2602|       Nagpur|       Mumbai|          1|         2020|       2020|\n",
      "|        2602|       Nagpur|       Mumbai|          1|         2020|       2021|\n",
      "|        2611|Visakhapatnam|        Kochi|          1|         2019|       2019|\n",
      "|        2602|       Nagpur|       Mumbai|          1|         2019|       2020|\n",
      "|        2605|       Mumbai|          Goa|          1|         2019|       2020|\n",
      "|        2571|        Delhi|       Kannur|          1|         2019|       2020|\n",
      "|        2607|       Mumbai|       Jaipur|          1|         2019|       2020|\n",
      "|        2507|   Chandigarh|       Mumbai|          1|         2019|       2020|\n",
      "|        2516|       Nagpur|        Delhi|          1|         2019|       2020|\n",
      "|        2511|        Delhi|        Patna|          1|         2019|       2020|\n",
      "|        2508|       Mumbai|        Delhi|          1|         2019|       2020|\n",
      "+------------+-------------+-------------+-----------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+----------+-----------+-----------+-------------+-----------+\n",
      "|flightNumber|    origin|destination|TotalFlight|validFromYear|validToYear|\n",
      "+------------+----------+-----------+-----------+-------------+-----------+\n",
      "|         803|Port Blair|  Bengaluru|          3|         2019|       2019|\n",
      "|         802| Bengaluru| Port Blair|          5|         2019|       2019|\n",
      "|         374| Bengaluru|     Ranchi|          4|         2020|       2020|\n",
      "|         375|    Ranchi|  Bengaluru|          4|         2020|       2020|\n",
      "+------------+----------+-----------+-----------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# jetAirWaysDF = spark.read.parquet(\"output/airline=AirAsia India/part-00000-2af11fb5-2af2-4daa-a534-2d12c4d68883.c000.snappy.parquet\")\n",
    "# jetAirWaysDF.show()\n",
    "# flightData.write.partitionBy(\"airline\").parquet(\"output\")\n",
    "\n",
    "airlineGoAir = spark.read.parquet(\"output/airline=GoAir\")\n",
    "airlineGoAir.show()\n",
    "\n",
    "airlineGoAir.createOrReplaceTempView(\"goAir\")\n",
    "goAirData = spark.sql(\"\"\" \n",
    "                    SELECT * FROM goAir where TotalFlight > 2\"\"\")\n",
    "goAirData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a39b8f50-ed16-4b7c-afde-e74c341663bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----------+-----------+-------------+-----------+----------------+\n",
      "|flightNumber|    origin|destination|TotalFlight|validFromYear|validToYear|flighPerformance|\n",
      "+------------+----------+-----------+-----------+-------------+-----------+----------------+\n",
      "|         803|Port Blair|  Bengaluru|          3|         2019|       2019|             Bad|\n",
      "|         802| Bengaluru| Port Blair|          5|         2019|       2019|            Good|\n",
      "|         374| Bengaluru|     Ranchi|          4|         2020|       2020|            Good|\n",
      "|         375|    Ranchi|  Bengaluru|          4|         2020|       2020|            Good|\n",
      "+------------+----------+-----------+-----------+-------------+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# jetAirWaysDF.createOrReplaceTempView(\"airasia\")\n",
    "\n",
    "# airasiasql = \"\"\"\n",
    "#     SELECT * from airasia where TotalFlight > 10 \"\"\"\n",
    "\n",
    "# airasia1 = spark.sql(airasiasql)\n",
    "# airasia1.show()\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def flightperformance(payload):\n",
    "    if payload > 3:\n",
    "        return \"Good\"\n",
    "    else:\n",
    "        return \"Bad\"\n",
    "regUDF = udf(flightperformance, StringType())\n",
    "goAirData = goAirData.withColumn(\"flighPerformance\", regUDF(goAirData[\"TotalFlight\"]))\n",
    "goAirData.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d8e96c6-19e8-41b1-bf7f-09a14e5e725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+-----------+-----------+-------------+-----------+\n",
      "|flightNumber|  origin|destination|TotalFlight|validFromYear|validToYear|\n",
      "+------------+--------+-----------+-----------+-------------+-----------+\n",
      "|         982|Bagdogra|    Chennai|          1|         2018|       2019|\n",
      "|         851|Bagdogra|      Delhi|          1|         2019|       2020|\n",
      "|         851|Bagdogra|      Delhi|          1|         2019|       2019|\n",
      "|         758|Bagdogra|      Delhi|          1|         2020|       2020|\n",
      "|         758|Bagdogra|      Delhi|          1|         2019|       2019|\n",
      "+------------+--------+-----------+-----------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- flightNumber: integer (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      " |-- TotalFlight: long (nullable = true)\n",
      " |-- validFromYear: integer (nullable = true)\n",
      " |-- validToYear: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import udf\n",
    "# from pyspark.sql.types import StringType\n",
    "\n",
    "# def flightStatus(payload):\n",
    "#     if payload >= 30:\n",
    "#         return \"Good\"\n",
    "#     else:\n",
    "#         return \"Bad\"\n",
    "# registerUDF = udf(flightStatus,StringType())\n",
    "# dfStatus = flightData.withColumn(\"flightCondition\", registerUDF(flightData[\"totalFlight\"]))\n",
    "# dfStatus.show()\n",
    "airlineGoAir.write.bucketBy(5,\"origin\") \\\n",
    "            .sortBy(\"origin\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .saveAsTable(\"flight_bucketed\")\n",
    "bucketed_df = spark.table(\"flight_bucketed\")\n",
    "bucketed_df.show(5)\n",
    "\n",
    "bucketed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63466bcd-a89e-496b-aeda-059afc3e39df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+-----------+-----------+-------------+-----------+----------------+--------------------+\n",
      "|flightNumber|    origin|destination|TotalFlight|validFromYear|validToYear|flighPerformance|      combined_array|\n",
      "+------------+----------+-----------+-----------+-------------+-----------+----------------+--------------------+\n",
      "|         803|Port Blair|  Bengaluru|          3|         2019|       2019|             Bad|[3, 2019, 2019, Bad]|\n",
      "|         802| Bengaluru| Port Blair|          5|         2019|       2019|            Good|[5, 2019, 2019, G...|\n",
      "|         374| Bengaluru|     Ranchi|          4|         2020|       2020|            Good|[4, 2020, 2020, G...|\n",
      "|         375|    Ranchi|  Bengaluru|          4|         2020|       2020|            Good|[4, 2020, 2020, G...|\n",
      "+------------+----------+-----------+-----------+-------------+-----------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filtered_df.printSchema()\n",
    "# dfStatus.createOrReplaceTempView(\"condition\")\n",
    "# conditionSql = \"\"\"\n",
    "#     SELECT flightNumber, MAX(totalFlight) as MaxVal FROM condition\n",
    "#     GROUP BY flightNumber\n",
    "#     ORDER BY MaxVal DESC\n",
    "#     \"\"\"\n",
    "# conditionTest = spark.sql(conditionSql)\n",
    "# conditionTest.show()\n",
    "# spark.sql(\"\"\"\n",
    "#     CREATE EXTERNAL TABLE flight_external (\n",
    "#         flightNumber Integer,\n",
    "#         airline STRING,\n",
    "#         destination STRING,\n",
    "#         TotalFlight long ,\n",
    "#         validFromYear Integer,\n",
    "#         validToYear Integer\n",
    "#     )\n",
    "#     PARTITIONED BY (origin STRING)\n",
    "#     STORED AS PARQUET\n",
    "#     LOCATION 'spark-warehouse/flight_bucketed'\n",
    "# \"\"\")\n",
    "# spark.sql(\"MSCK REPAIR TABLE flight_external\")\n",
    "\n",
    "# spark.sql(\"\"\"\n",
    "#     SELECT flightNumber, airline, destination, validFrom\n",
    "#     FROM flight_external\n",
    "#     WHERE origin = 'Delhi'\n",
    "# \"\"\").show(5)\n",
    "from pyspark.sql.functions import array\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "goAirData = goAirData.withColumn(\n",
    "    \"combined_array\",\n",
    "    array(\"TotalFlight\", \"validFromYear\", \"validToYear\", \"flighPerformance\")\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "goAirData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34544da2-5fbb-47a0-8781-eec599804e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------------+\n",
      "|flightNumber|MaxVal|AddCondition|\n",
      "+------------+------+------------+\n",
      "|         559|    90|          91|\n",
      "|         612|    86|          87|\n",
      "|        2197|    71|          72|\n",
      "|         611|    71|          72|\n",
      "|         238|    66|          67|\n",
      "|         748|    62|          63|\n",
      "|         287|    62|          63|\n",
      "|        1451|    56|          57|\n",
      "|         496|    50|          51|\n",
      "|        1427|    50|          51|\n",
      "|         634|    46|          47|\n",
      "|         406|    45|          46|\n",
      "|        2148|    45|          46|\n",
      "|         237|    45|          46|\n",
      "|         802|    45|          46|\n",
      "|         587|    43|          44|\n",
      "|        6325|    43|          44|\n",
      "|         741|    43|          44|\n",
      "|        1426|    41|          42|\n",
      "|         477|    41|          42|\n",
      "+------------+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filtered_df.select(\"origin\",\"destination\", \"dayOfWeek\").distinct().show()\n",
    "from pyspark.sql.types import IntegerType\n",
    "def addData(payload):\n",
    "    if payload > 30:\n",
    "        return payload + 1\n",
    "    else:\n",
    "        return payload + 10\n",
    "registerAddData = udf(addData, IntegerType())\n",
    "dfAddData =  conditionTest.withColumn(\"AddCondition\", registerAddData(conditionTest[\"MaxVal\"]))\n",
    "dfAddData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cc8ce0d-a18a-4559-b271-187310bfb244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+------------+\n",
      "|flightNumber|MaxVal|AddCondition|\n",
      "+------------+------+------------+\n",
      "|        3071|    11|          21|\n",
      "|        2554|    11|          21|\n",
      "|        2031|    11|          21|\n",
      "|        7993|    11|          21|\n",
      "|         727|    11|          21|\n",
      "|        3220|    11|          21|\n",
      "|         686|    11|          21|\n",
      "|        7206|    11|          21|\n",
      "|        7265|    11|          21|\n",
      "|         321|    11|          21|\n",
      "|        7989|    11|          21|\n",
      "|        2871|    11|          21|\n",
      "|         367|    11|          21|\n",
      "|        1516|    11|          21|\n",
      "|         191|    11|          21|\n",
      "|        8144|    11|          21|\n",
      "|        1721|    11|          21|\n",
      "|         760|    11|          21|\n",
      "|         961|    11|          21|\n",
      "|         328|    11|          21|\n",
      "+------------+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import col, when, split, array_contains\n",
    "\n",
    "# days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "# df_split = df1.withColumn(\"dayOfWeek_array\", split(col(\"dayOfWeek\"), \",\"))\n",
    "\n",
    "# for day in days:\n",
    "#     df_split = df_split.withColumn(\n",
    "#         day,\n",
    "#         when(array_contains(col(\"dayOfWeek_array\"), day), 1).otherwise(0)\n",
    "#     )\n",
    "\n",
    "# df_result = df_split.drop(\"dayOfWeek_array\")\n",
    "\n",
    "# # Show the result\n",
    "# df_result.show()\n",
    "\n",
    "# # Print schema to verify new columns\n",
    "# df_result.printSchema()\n",
    "dfAddData.createOrReplaceTempView(\"dataview\")\n",
    "maxSql = \"\"\"\n",
    "    SELECT * FROM dataview where MaxVal > 10\n",
    "    ORDER BY MaxVal ASC \"\"\"\n",
    "maxsql1 = spark.sql(maxSql)\n",
    "maxsql1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c18b7f3-39d9-4a23-b6a5-d0382783fe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+----------------------+------+-------+---------+--------+------+--------+------+\n",
      "|flightNumber|    airline|scheduledDepartureTime|Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday|\n",
      "+------------+-----------+----------------------+------+-------+---------+--------+------+--------+------+\n",
      "|         635|  Air India|   2025-04-12 09:15:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         849|  Air India|   2025-04-12 16:10:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         148|Jet Airways|   2025-04-12 19:50:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         986| TestIndigo|   2025-04-12 11:40:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         473| TestIndigo|   2025-04-12 21:10:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|        7106| TestIndigo|   2025-04-12 08:10:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|        7989| TestIndigo|   2025-04-12 15:00:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         523|   SpiceJet|   2025-04-12 19:25:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         129|      GoAir|   2025-04-12 11:10:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         654|  Air India|   2025-04-12 08:45:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         905| TestIndigo|   2025-04-12 11:05:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|        7155| TestIndigo|   2025-04-12 15:35:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|        7107| TestIndigo|   2025-04-12 09:40:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         511|    Vistara|   2025-04-12 17:05:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         942|   SpiceJet|   2025-04-12 16:25:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|        7195| TestIndigo|   2025-04-12 10:45:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         232| TestIndigo|   2025-04-12 21:20:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         382| TestIndigo|   2025-04-12 11:10:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|        6269| TestIndigo|   2025-04-12 07:55:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "|         516|     TruJet|   2025-04-12 15:10:00|     1|      1|        1|       1|     1|       1|     1|\n",
      "+------------+-----------+----------------------+------+-------+---------+--------+------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_result.filter(\n",
    "    (col(\"Monday\") == 1) &\n",
    "    (col(\"Tuesday\") == 1) &\n",
    "    (col(\"Wednesday\") == 1) &\n",
    "    (col(\"Thursday\") == 1) &\n",
    "    (col(\"Friday\") == 1) &\n",
    "    (col(\"Saturday\") == 1) &\n",
    "    (col(\"Sunday\") == 1)\n",
    ").select(\"flightNumber\",\"airline\",\"scheduledDepartureTime\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e426415d-1313-47da-9709-238a204e0fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+\n",
      "|date|year|month|\n",
      "+----+----+-----+\n",
      "+----+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date,month, year\n",
    "\n",
    "df_with_month = df1.withColumn(\"validFrom\", to_date(col(\"scheduledDepartureTime\"))) \\\n",
    "                    .withColumn(\"year\", year(col(\"date\"))) \\\n",
    "                    .withColumn(\"month\", month(col(\"date\")))\n",
    "\n",
    "df_with_month.filter(col(\"month\") != 4 ).select(\"date\", \"year\",\"month\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "315bb8e6-9aaf-4706-9de1-1f2a9254695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+-----+------------+\n",
      "|      airline|year|month|flight_count|\n",
      "+-------------+----+-----+------------+\n",
      "|         NULL|NULL| NULL|         595|\n",
      "|         NULL|2025|    4|        1291|\n",
      "|    Air India|NULL| NULL|        1108|\n",
      "|    Air India|2025|    4|        2379|\n",
      "|AirAsia India|NULL| NULL|         664|\n",
      "|AirAsia India|2025|    4|        1699|\n",
      "|        GoAir|NULL| NULL|        1380|\n",
      "|        GoAir|2025|    4|        2449|\n",
      "|  Jet Airways|NULL| NULL|         325|\n",
      "|  Jet Airways|2025|    4|         903|\n",
      "|      Jetlite|NULL| NULL|          23|\n",
      "|      Jetlite|2025|    4|          82|\n",
      "|     SpiceJet|NULL| NULL|        1262|\n",
      "|     SpiceJet|2025|    4|        3262|\n",
      "|   TestIndigo|NULL| NULL|        4458|\n",
      "|   TestIndigo|2025|    4|       10137|\n",
      "|       TruJet|NULL| NULL|         173|\n",
      "|       TruJet|2025|    4|         382|\n",
      "|      Vistara|NULL| NULL|         590|\n",
      "|      Vistara|2025|    4|        1163|\n",
      "+-------------+----+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_grouped = df_with_month.groupBy(\"airline\",\"year\", \"month\") \\\n",
    "                            .agg({\"FlightNumber\":\"count\"}) \\\n",
    "                            .withColumnRenamed(\"count(flightNumber)\", \"flight_count\") \\\n",
    "                            .orderBy(\"airline\", \"year\",\"month\")\n",
    "df_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c1d5fdb-b491-46c7-a053-aafd445962ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-------+-----------+--------------------+----------------------+--------------------+----------+----------+\n",
      "|flightNumber|airline| origin|destination|           dayOfWeek|scheduledDepartureTime|scheduledArrivalTime| validFrom|   validTo|\n",
      "+------------+-------+-------+-----------+--------------------+----------------------+--------------------+----------+----------+\n",
      "|         425|  GoAir|  Delhi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-12 05:45:00|                NULL|28-10-2018|30-03-2019|\n",
      "|         423|  GoAir|  Delhi|  Hyderabad|            Saturday|   2025-04-12 07:30:00|                NULL|28-10-2018|28-10-2018|\n",
      "|         423|  GoAir|  Delhi|  Hyderabad|              Friday|   2025-04-12 07:30:00|                NULL|03-11-2018|01-12-2018|\n",
      "|         423|  GoAir|  Delhi|  Hyderabad|              Friday|   2025-04-12 07:30:00|                NULL|02-02-2019|30-03-2019|\n",
      "|         423|  GoAir|  Delhi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-12 07:30:00|                NULL|29-10-2018|30-11-2018|\n",
      "|         423|  GoAir|  Delhi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-12 07:30:00|                NULL|01-02-2019|29-03-2019|\n",
      "|         423|  GoAir|  Delhi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-12 07:30:00|                NULL|02-12-2018|31-01-2019|\n",
      "|         422|  GoAir|  Delhi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-12 20:55:00|                NULL|28-10-2018|30-03-2019|\n",
      "|         559|  GoAir|Lucknow|  Hyderabad|Sunday,Tuesday,We...|   2025-04-12 15:45:00| 2025-04-12 17:45:00|28-10-2018|30-03-2019|\n",
      "|         580|  GoAir|  Kochi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-12 04:45:00| 2025-04-12 06:15:00|28-10-2018|30-03-2019|\n",
      "+------------+-------+-------+-----------+--------------------+----------------------+--------------------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"Flight_Schedule.csv\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfba5b0c-050f-45fb-b1f6-a73d2aa926f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+----------+--------------+---------------+-------------+----------+------------+-------------+-----------+\n",
      "|      airline|flightNumber| validFrom|validFrom_year|validFrom_month|validFrom_day|   validTo|validTo_year|validTo_month|validTo_day|\n",
      "+-------------+------------+----------+--------------+---------------+-------------+----------+------------+-------------+-----------+\n",
      "|        GoAir|         468|01-12-2018|          2018|             12|            1|30-03-2019|        2019|            3|         30|\n",
      "|        GoAir|         418|29-10-2018|          2018|             10|           29|30-03-2019|        2019|            3|         30|\n",
      "|    Air India|         853|28-10-2018|          2018|             10|           28|30-03-2019|        2019|            3|         30|\n",
      "|    Air India|         421|30-10-2018|          2018|             10|           30|22-11-2018|        2018|           11|         22|\n",
      "|AirAsia India|         783|28-10-2018|          2018|             10|           28|30-03-2019|        2019|            3|         30|\n",
      "|  Jet Airways|         339|28-10-2018|          2018|             10|           28|30-03-2019|        2019|            3|         30|\n",
      "|  Jet Airways|        3566|29-10-2018|          2018|             10|           29|29-03-2019|        2019|            3|         29|\n",
      "|  Jet Airways|         313|28-10-2018|          2018|             10|           28|30-03-2019|        2019|            3|         30|\n",
      "|  Jet Airways|         889|15-03-2019|          2019|              3|           15|30-03-2019|        2019|            3|         30|\n",
      "|  Jet Airways|         649|15-02-2019|          2019|              2|           15|30-03-2019|        2019|            3|         30|\n",
      "|   TestIndigo|        2454|30-10-2018|          2018|             10|           30|26-03-2019|        2019|            3|         26|\n",
      "|   TestIndigo|         953|28-10-2018|          2018|             10|           28|30-03-2019|        2019|            3|         30|\n",
      "|   TestIndigo|         135|28-10-2018|          2018|             10|           28|29-03-2019|        2019|            3|         29|\n",
      "|   TestIndigo|         368|30-11-2018|          2018|             11|           30|30-11-2018|        2018|           11|         30|\n",
      "|   TestIndigo|         502|28-10-2018|          2018|             10|           28|29-03-2019|        2019|            3|         29|\n",
      "|   TestIndigo|         505|03-11-2018|          2018|             11|            3|30-03-2019|        2019|            3|         30|\n",
      "|      Vistara|         813|28-10-2018|          2018|             10|           28|30-03-2019|        2019|            3|         30|\n",
      "|      Vistara|         731|30-10-2018|          2018|             10|           30|26-03-2019|        2019|            3|         26|\n",
      "|       TruJet|         706|28-10-2018|          2018|             10|           28|30-03-2019|        2019|            3|         30|\n",
      "|       TruJet|         536|28-10-2018|          2018|             10|           28|30-03-2019|        2019|            3|         30|\n",
      "+-------------+------------+----------+--------------+---------------+-------------+----------+------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- flightNumber: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- destination: string (nullable = true)\n",
      " |-- dayOfWeek: string (nullable = true)\n",
      " |-- scheduledDepartureTime: timestamp (nullable = true)\n",
      " |-- scheduledArrivalTime: timestamp (nullable = true)\n",
      " |-- validFrom: string (nullable = true)\n",
      " |-- validTo: string (nullable = true)\n",
      " |-- validFrom_date: date (nullable = true)\n",
      " |-- validFrom_year: integer (nullable = true)\n",
      " |-- validFrom_month: integer (nullable = true)\n",
      " |-- validFrom_day: integer (nullable = true)\n",
      " |-- validTo_date: date (nullable = true)\n",
      " |-- validTo_year: integer (nullable = true)\n",
      " |-- validTo_month: integer (nullable = true)\n",
      " |-- validTo_day: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date, year, month, dayofmonth\n",
    "\n",
    "splitDate = df.withColumn(\"validFrom_date\", to_date(col(\"validFrom\"), \"dd-MM-yyyy\")) \\\n",
    "                        .withColumn(\"validFrom_year\", year(col(\"validFrom_date\"))) \\\n",
    "                        .withColumn(\"validFrom_month\", month(col(\"validFrom_date\"))) \\\n",
    "                        .withColumn(\"validFrom_day\", dayofmonth(col(\"validFrom_date\"))) \\\n",
    "                        .withColumn(\"validTo_date\", to_date(col(\"validTo\"), \"dd-MM-yyyy\")) \\\n",
    "                        .withColumn(\"validTo_year\", year(col(\"validTo_date\"))) \\\n",
    "                        .withColumn(\"validTo_month\", month(col(\"validTo_date\"))) \\\n",
    "                        .withColumn(\"validTo_day\", dayofmonth(col(\"validTo_date\")))\n",
    "splitDate.select(\n",
    "    \"airline\", \"flightNumber\",\"validFrom\", \"validFrom_year\", \"validFrom_month\", \"validFrom_day\",\n",
    "    \"validTo\", \"validTo_year\", \"validTo_month\", \"validTo_day\"\n",
    ").distinct().show()\n",
    "splitDate.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d276f5-ba6b-434c-805e-31a8d564ca26",
   "metadata": {},
   "outputs": [],
   "source": [
    "airlineDataByYear = splitDate.write \\\n",
    "                    .partitionBy(\"airline\", \"validFrom_year\",\"validFrom_month\") \\\n",
    "                    .mode(\"overwrite\") \\\n",
    "                    .parquet(\"output/flight_schedule_partitioned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78d7ef73-d4fd-4e31-9a31-5e6ab88912c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+-----------+--------------------+----------------------+--------------------+----------+----------+--------------+-------------+------------+------------+-------------+-----------+\n",
      "|flightNumber| origin|destination|           dayOfWeek|scheduledDepartureTime|scheduledArrivalTime| validFrom|   validTo|validFrom_date|validFrom_day|validTo_date|validTo_year|validTo_month|validTo_day|\n",
      "+------------+-------+-----------+--------------------+----------------------+--------------------+----------+----------+--------------+-------------+------------+------------+-------------+-----------+\n",
      "|         425|  Delhi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-12 05:45:00|                NULL|28-10-2018|30-03-2019|    2018-10-28|           28|  2019-03-30|        2019|            3|         30|\n",
      "|         423|  Delhi|  Hyderabad|            Saturday|   2025-04-12 07:30:00|                NULL|28-10-2018|28-10-2018|    2018-10-28|           28|  2018-10-28|        2018|           10|         28|\n",
      "|         423|  Delhi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-12 07:30:00|                NULL|29-10-2018|30-11-2018|    2018-10-29|           29|  2018-11-30|        2018|           11|         30|\n",
      "|         422|  Delhi|  Hyderabad|Sunday,Monday,Tue...|   2025-04-12 20:55:00|                NULL|28-10-2018|30-03-2019|    2018-10-28|           28|  2019-03-30|        2019|            3|         30|\n",
      "|         559|Lucknow|  Hyderabad|Sunday,Tuesday,We...|   2025-04-12 15:45:00| 2025-04-12 17:45:00|28-10-2018|30-03-2019|    2018-10-28|           28|  2019-03-30|        2019|            3|         30|\n",
      "+------------+-------+-----------+--------------------+----------------------+--------------------+----------+----------+--------------+-------------+------------+------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_verify = spark.read.parquet(\"output/flight_schedule_partitioned/airline=GoAir/validFrom_year=2018/validFrom_month=10\")\n",
    "df_verify.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88baab1-9b04-472e-a343-0a6de6c78c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
