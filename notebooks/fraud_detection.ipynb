{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cbe2d7-9911-447f-8cbb-c34e3115aa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark ready: 3.5.3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, expr, concat, lit\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType, LongType\n",
    "import pyspark.sql.functions as F\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "BOOTSTRAP = \"broker:29094\"   # inside Docker network\n",
    "TXN_TOPIC = \"transaction\"\n",
    "METRICS_TOPIC = \"metrics\"\n",
    "mode = \"salting\"   # \"baseline\", \"broadcast\", or \"salting\"\n",
    "enable_aqe = True\n",
    "SKEW_CARD = \"4111-1111-1111-1111\"\n",
    "# ----------------------------\n",
    "# Spark Session\n",
    "# ----------------------------\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"fraud-detection-demo\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"6\") \\\n",
    "    .getOrCreate()\n",
    "print(\"✅ Spark ready:\", spark.version)\n",
    "\n",
    "if enable_aqe:\n",
    "    spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "\n",
    "# ----------------------------\n",
    "# Input schema & Kafka source\n",
    "# ----------------------------\n",
    "schema = StructType() \\\n",
    "    .add(\"txn_id\", LongType()) \\\n",
    "    .add(\"card_number\", StringType()) \\\n",
    "    .add(\"amount\", DoubleType()) \\\n",
    "    .add(\"merchant\", StringType()) \\\n",
    "    .add(\"ts\", LongType())\n",
    "\n",
    "kdf = spark.readStream.format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", BOOTSTRAP) \\\n",
    "    .option(\"subscribe\", TXN_TOPIC) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"failOnDataLoss\", \"false\") \\\n",
    "    .load()\n",
    "txn_df = kdf.select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"j\")).select(\"j.*\")\n",
    "\n",
    "# ----------------------------\n",
    "# Lookup table (risk profiles)\n",
    "# ----------------------------\n",
    "risk_profiles = spark.createDataFrame([\n",
    "    (\"4111-1111-1111-1111\", \"high\"),\n",
    "    (\"4000-0000-0000-0002\", \"medium\"),\n",
    "    (\"4000-0000-0000-0003\", \"low\")\n",
    "], [\"card_number\", \"risk_level\"])\n",
    "\n",
    "# ----------------------------\n",
    "# Join strategies\n",
    "# ----------------------------\n",
    "if mode == \"baseline\":\n",
    "    joined = txn_df.join(risk_profiles, \"card_number\", \"left\")\n",
    "\n",
    "elif mode == \"broadcast\":\n",
    "    joined = txn_df.join(F.broadcast(risk_profiles), \"card_number\", \"left\")\n",
    "\n",
    "elif mode == \"salting\":\n",
    "    SALT_N = 6\n",
    "    salts = spark.range(0, SALT_N).selectExpr(\"id as salt\")\n",
    "    lookup_salted = risk_profiles.crossJoin(salts) \\\n",
    "        .withColumn(\"salted_card\", concat(col(\"card_number\"), lit(\"_\"), col(\"salt\"))) \\\n",
    "        .select(\"salted_card\", \"risk_level\")\n",
    "\n",
    "    salted_stream = txn_df.withColumn(\n",
    "        \"salt\",\n",
    "        expr(f\"CASE WHEN card_number='{SKEW_CARD}' THEN floor(rand()*{SALT_N}) ELSE 0 END\")\n",
    "    ).withColumn(\"salted_card\", concat(col(\"card_number\"), lit(\"_\"), col(\"salt\")))\n",
    "\n",
    "    joined = salted_stream.join(\n",
    "        lookup_salted,\n",
    "        salted_stream.salted_card == lookup_salted.salted_card,\n",
    "        \"left\"\n",
    "    ).drop(\"salted_card\")\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics sender\n",
    "# ----------------------------\n",
    "def send_metrics(batch_df, batch_id):\n",
    "    total = batch_df.count()\n",
    "    risky = batch_df.filter(\"risk_level='high'\").count()\n",
    "    metrics = {\n",
    "        \"batch_id\": int(batch_id),\n",
    "        \"mode\": mode,\n",
    "        \"total_txns\": int(total),\n",
    "        \"high_risk_txns\": int(risky),\n",
    "        \"fraud_ratio\": round(risky / total, 3) if total > 0 else 0\n",
    "    }\n",
    "    print(f\"[Metrics] {metrics}\")\n",
    "\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=BOOTSTRAP,\n",
    "        value_serializer=lambda v: json.dumps(v).encode(\"utf-8\")\n",
    "    )\n",
    "    producer.send(METRICS_TOPIC, value=metrics)\n",
    "    producer.flush()\n",
    "    producer.close()\n",
    "\n",
    "# ----------------------------\n",
    "# Write stream\n",
    "# ----------------------------\n",
    "query = joined.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .foreachBatch(lambda df, bid: (df.show(5, truncate=False), send_metrics(df, bid))) \\\n",
    "    .option(\"checkpointLocation\", f\"/opt/output/fraud_checkpoint_{mode}\") \\\n",
    "    .start()\n",
    "\n",
    "joined.select(\"txn_id\", \"card_number\", \"amount\", \"risk_level\").writeStream \\\n",
    "    .format(\"console\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .option(\"truncate\", False) \\\n",
    "    .start() \\\n",
    "    .awaitTermination()\n",
    "\n",
    "query.awaitTermination(60)\n",
    "query.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a009295b-e668-4f91-a67f-da693bb7e90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SparkSession.stop of <pyspark.sql.session.SparkSession object at 0x7f4438a93ee0>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8934b251-8f7e-4b02-936e-f2333f46d9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
