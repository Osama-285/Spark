{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76091b62-efce-435e-8d2c-d8fd405acd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"RDDEamples\").getOrCreate()\n",
    "spark\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef13061-e453-4676-b3fc-07534b082f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flights_rdd PythonRDD[6] at RDD at PythonRDD.scala:53\n",
      "['AirAsia India', 'Jet Airways', 'TestIndigo', 'Vistara', '', 'GoAir', 'Air India', 'Jetlite', 'SpiceJet']\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.textFile(\"Flight_Schedule.csv\")\n",
    "header = rdd.first()\n",
    "rdd_no_header = rdd.filter(lambda line: line != header)\n",
    "\n",
    "def parse_flight(line):\n",
    "    fields = line.split(\",\")\n",
    "    return (fields[0],fields[1],fields[2],fields[3])\n",
    "\n",
    "flights_rdd = rdd_no_header.map(parse_flight)\n",
    "print(\"flights_rdd\",flights_rdd)\n",
    "\n",
    "delhi_flights = flights_rdd.filter(lambda x:x[2] == \"Delhi\")\n",
    "\n",
    "airlines = delhi_flights.map(lambda x:x[1]).distinct().collect()\n",
    "print(airlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa7c02d-41f6-4d6c-ae80-f87e2c627ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flights with null scheduledArrivalTime: 4068\n"
     ]
    }
   ],
   "source": [
    "null_arrival_count = sc.accumulator(0)\n",
    "\n",
    "def count_nulls(line):\n",
    "    fields = line.split(\",\")\n",
    "    if len(fields) > 6 and fields[6] == \"\":\n",
    "        null_arrival_count.add(1)\n",
    "\n",
    "rdd_no_header.foreach(count_nulls)\n",
    "print(f\"Flights with null scheduledArrivalTime: {null_arrival_count.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8c5387-5d8c-40e4-a334-0f8bccd76e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('425', 'GoAir', 'Delhi', 'Hyderabad')\n",
      "('423', 'GoAir', 'Delhi', 'Hyderabad')\n"
     ]
    }
   ],
   "source": [
    "# List of airlines\n",
    "target_airlines = [\"GoAir\", \"SpiceJet\"]\n",
    "\n",
    "# Broadcast it\n",
    "broadcast_airlines = sc.broadcast(target_airlines)\n",
    "\n",
    "# Filter flights\n",
    "filtered_flights = flights_rdd.filter(lambda x: x[1] in broadcast_airlines.value)\n",
    "\n",
    "# Show first 2\n",
    "for flight in filtered_flights.take(2):\n",
    "    print(flight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e25f2bf-eceb-46da-8833-d517b5975c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers in each box: [(0, 6002), (1, 4489), (2, 15823), (3, 8011)]\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.textFile(\"Flight_Schedule.csv\")\n",
    "\n",
    "header = rdd.first()\n",
    "rdd_no_header = rdd.filter(lambda line: line != header)\n",
    "\n",
    "rdd_pairs = rdd_no_header.map(lambda line: (line.split(\",\")[1], line))\n",
    "\n",
    "def sort_airline(airline):\n",
    "    return hash(airline) % 4\n",
    "\n",
    "sorted_rdd = rdd_pairs.partitionBy(4, sort_airline)\n",
    "\n",
    "def count_papers(box_number, papers):\n",
    "    return [(box_number, sum(1 for _ in papers))]\n",
    "\n",
    "counts = sorted_rdd.mapPartitionsWithIndex(count_papers).collect()\n",
    "print(\"Papers in each box:\", counts)\n",
    "\n",
    "# Save to see the groups\n",
    "sorted_rdd.map(lambda x: x[1]).saveAsTextFile(\"rddoutput\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8d43f9-9f1f-4d44-8150-68b139b5384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\", \"true\").csv(\"Flight_Schedule.csv\")\n",
    "df.write.partitionBy(\"airline\").parquet(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de7f76-edd9-4953-955f-90382add4013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
